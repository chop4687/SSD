{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from layers import *\n",
    "from data import voc, coco\n",
    "import os\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    \"\"\"Single Shot Multibox Architecture\n",
    "    The network is composed of a base VGG network followed by the\n",
    "    added multibox conv layers.  Each multibox layer branches into\n",
    "        1) conv2d for class conf scores\n",
    "        2) conv2d for localization predictions\n",
    "        3) associated priorbox layer to produce default bounding\n",
    "           boxes specific to the layer's feature map size.\n",
    "    See: https://arxiv.org/pdf/1512.02325.pdf for more details.\n",
    "\n",
    "    Args:\n",
    "        phase: (string) Can be \"test\" or \"train\"\n",
    "        size: input image size\n",
    "        base: VGG16 layers for input, size of either 300 or 500\n",
    "        extras: extra layers that feed to multibox loc and conf layers\n",
    "        head: \"multibox head\" consists of loc and conf conv layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, phase, size, base, extras, head, num_classes):\n",
    "        super(SSD, self).__init__()\n",
    "        self.phase = phase\n",
    "        self.num_classes = num_classes\n",
    "        self.cfg = (coco, voc)[num_classes == 21]\n",
    "        self.priorbox = PriorBox(self.cfg)\n",
    "        self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
    "        self.size = size\n",
    "\n",
    "        # SSD network\n",
    "        self.vgg = nn.ModuleList(base)\n",
    "        # Layer learns to scale the l2 normalized features from conv4_3\n",
    "        self.L2Norm = L2Norm(512, 20)\n",
    "        self.extras = nn.ModuleList(extras)\n",
    "\n",
    "        self.loc = nn.ModuleList(head[0])\n",
    "        self.conf = nn.ModuleList(head[1])\n",
    "\n",
    "        if phase == 'val':\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            self.detect = Detect(num_classes, 0, 200, 0.01, 0.45)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies network layers and ops on input image(s) x.\n",
    "\n",
    "        Args:\n",
    "            x: input image or batch of images. Shape: [batch,3,300,300].\n",
    "\n",
    "        Return:\n",
    "            Depending on phase:\n",
    "            test:\n",
    "                Variable(tensor) of output class label predictions,\n",
    "                confidence score, and corresponding location predictions for\n",
    "                each object detected. Shape: [batch,topk,7]\n",
    "\n",
    "            train:\n",
    "                list of concat outputs from:\n",
    "                    1: confidence layers, Shape: [batch*num_priors,num_classes]\n",
    "                    2: localization layers, Shape: [batch,num_priors*4]\n",
    "                    3: priorbox layers, Shape: [2,num_priors*4]\n",
    "        \"\"\"\n",
    "        sources = list()\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "\n",
    "        # apply vgg up to conv4_3 relu\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "        s = self.L2Norm(x)\n",
    "        sources.append(s)\n",
    "\n",
    "        # apply vgg up to fc7\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        sources.append(x)\n",
    "\n",
    "        # apply extra layers and cache source layer outputs\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "        # apply multibox head to source layers\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        if self.phase == \"val\":\n",
    "            output = self.detect(\n",
    "                loc.view(loc.size(0), -1, 4),                   # loc preds\n",
    "                self.softmax(conf.view(conf.size(0), -1,\n",
    "                             self.num_classes)),                # conf preds\n",
    "                self.priors.type(type(x.data))                  # default boxes\n",
    "            )\n",
    "        else:\n",
    "            output = (\n",
    "                loc.view(loc.size(0), -1, 4),\n",
    "                conf.view(conf.size(0), -1, self.num_classes),\n",
    "                self.priors\n",
    "            )\n",
    "        return output\n",
    "\n",
    "    def load_weights(self, base_file):\n",
    "        other, ext = os.path.splitext(base_file)\n",
    "        if ext == '.pkl' or '.pth':\n",
    "            print('Loading weights into state dict...')\n",
    "            self.load_state_dict(torch.load(base_file,\n",
    "                                 map_location=lambda storage, loc: storage))\n",
    "            print('Finished!')\n",
    "        else:\n",
    "            print('Sorry only .pth and .pkl files supported.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multibox(num_classes):\n",
    "    vgg = []\n",
    "    # conv2d = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "    # conv2d = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "    # conv2d = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "    # conv2d = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "    # vgg += [conv2d, nn.ReLU(inplace=True)]\n",
    "\n",
    "    vgg_pretrained = models.vgg16(pretrained=True).features[:-1]\n",
    "    vgg_pretrained[16] = nn.MaxPool2d(kernel_size=2, stride=2,padding=0, dilation=1 , ceil_mode=True)\n",
    "    for i in range(len(vgg_pretrained)) :\n",
    "        vgg += [vgg_pretrained[i]]\n",
    "    vgg += [nn.MaxPool2d(kernel_size=3, stride=1,padding=1, dilation=1 , ceil_mode=False)]\n",
    "    vgg += [nn.Conv2d(512,1024,kernel_size=(3,3),stride=(1,1),padding=(6,6),dilation=(6,6))]\n",
    "    vgg += [nn.ReLU(inplace=True)]\n",
    "    vgg += [nn.Conv2d(1024,1024,kernel_size=(1,1),stride=(1,1))]\n",
    "    vgg += [nn.ReLU(inplace=True)]\n",
    "\n",
    "    extra_layers = []\n",
    "    extra_layers += [nn.Conv2d(1024, 256, kernel_size=(1, 1),stride=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2,2), padding=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(512, 128, kernel_size=(1, 1),stride=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2,2), padding=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(256, 128, kernel_size=(1, 1),stride=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(128, 256, kernel_size=(3, 3),stride=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(256, 128, kernel_size=(1, 1),stride=(1,1))]\n",
    "    extra_layers += [nn.Conv2d(128, 256, kernel_size=(3, 3),stride=(1,1))]\n",
    "\n",
    "\n",
    "    loc_layers = []\n",
    "    loc_layers += [nn.Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    loc_layers += [nn.Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    loc_layers += [nn.Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    loc_layers += [nn.Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    loc_layers += [nn.Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    loc_layers += [nn.Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "\n",
    "    conf_layers = []\n",
    "    conf_layers += [nn.Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    conf_layers += [nn.Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    conf_layers += [nn.Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    conf_layers += [nn.Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    conf_layers += [nn.Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "    conf_layers += [nn.Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
    "\n",
    "    return vgg, extra_layers, (loc_layers, conf_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ssd(phase, size=300, num_classes=21):\n",
    "    base_, extras_, head_ = multibox(num_classes)\n",
    "    return SSD(phase, size, base_, extras_, head_, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
