{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"show.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LnmCoNaC6sr8","colab_type":"code","outputId":"097aaf63-c466-4643-db91-5dcd888f3cf9","executionInfo":{"status":"ok","timestamp":1576572248115,"user_tz":-540,"elapsed":2792,"user":{"displayName":"강준규","photoUrl":"","userId":"00670362314563668003"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!git clone https://github.com/chop4687/SSD.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'SSD' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eGUP9V5Z6tbn","colab_type":"code","outputId":"d0cf13c7-726e-4334-f8fb-dc6cb97b0c9e","executionInfo":{"status":"ok","timestamp":1576572250135,"user_tz":-540,"elapsed":4788,"user":{"displayName":"강준규","photoUrl":"","userId":"00670362314563668003"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tue Dec 17 08:44:09 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GzdCQtqf02u6","colab_type":"code","colab":{}},"source":["from tqdm import tqdm_notebook as tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjD1KXgY67xz","colab_type":"code","outputId":"e5984d03-e893-41b6-9099-d1b1e99c3699","executionInfo":{"status":"ok","timestamp":1576572273388,"user_tz":-540,"elapsed":28005,"user":{"displayName":"강준규","photoUrl":"","userId":"00670362314563668003"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["from torchvision import datasets\n","datasets.VOCDetection(root='SSD/', year='2007', download=True)\n","datasets.VOCDetection(root='SSD/', year='2012', download=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using downloaded and verified file: SSD/VOCtrainval_06-Nov-2007.tar\n","Using downloaded and verified file: SSD/VOCtrainval_11-May-2012.tar\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Dataset VOCDetection\n","    Number of datapoints: 5717\n","    Root location: SSD/"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"us-iLujMMEuO","colab_type":"code","colab":{}},"source":["import sys\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","sys.path.append('/content/SSD')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XZPxVlMtxjM","colab_type":"code","colab":{}},"source":["from data import *\n","from utils.augmentations import SSDAugmentation\n","from layers.modules import MultiBoxLoss\n","from ssd import SSD\n","import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","import time\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torch.nn.init as init\n","import torch.utils.data as data\n","import numpy as np\n","import argparse\n","from torch.nn.parallel.data_parallel import DataParallel\n","from torchvision import models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CereAp3NNTc","colab_type":"code","colab":{}},"source":["def multibox(num_classes):\n","    vgg = []\n","    # conv2d = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","    # conv2d = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","    # conv2d = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n","    # conv2d = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # vgg += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","    # conv2d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","    # vgg += [conv2d, nn.ReLU(inplace=True)]\n","\n","    vgg_pretrained = models.vgg16(pretrained=True).features[:-1]\n","    vgg_pretrained[16] = nn.MaxPool2d(kernel_size=2, stride=2,padding=0, dilation=1 , ceil_mode=True)\n","    for i in range(len(vgg_pretrained)) :\n","        vgg += [vgg_pretrained[i]]\n","    vgg += [nn.MaxPool2d(kernel_size=3, stride=1,padding=1, dilation=1 , ceil_mode=False)]\n","    vgg += [nn.Conv2d(512,1024,kernel_size=(3,3),stride=(1,1),padding=(6,6),dilation=(6,6))]\n","    vgg += [nn.ReLU(inplace=True)]\n","    vgg += [nn.Conv2d(1024,1024,kernel_size=(1,1),stride=(1,1))]\n","    vgg += [nn.ReLU(inplace=True)]\n","\n","    extra_layers = []\n","    extra_layers += [nn.Conv2d(1024, 256, kernel_size=(1, 1),stride=(1,1))]\n","    extra_layers += [nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2,2), padding=(1,1))]\n","    extra_layers += [nn.Conv2d(512, 128, kernel_size=(1, 1),stride=(1,1))]\n","    extra_layers += [nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2,2), padding=(1,1))]\n","    extra_layers += [nn.Conv2d(256, 128, kernel_size=(1, 1),stride=(1,1))]\n","    extra_layers += [nn.Conv2d(128, 256, kernel_size=(3, 3),stride=(1,1))]\n","    extra_layers += [nn.Conv2d(256, 128, kernel_size=(1, 1),stride=(1,1))]\n","    extra_layers += [nn.Conv2d(128, 256, kernel_size=(3, 3),stride=(1,1))]\n","\n","\n","    loc_layers = []\n","    loc_layers += [nn.Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    loc_layers += [nn.Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    loc_layers += [nn.Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    loc_layers += [nn.Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    loc_layers += [nn.Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    loc_layers += [nn.Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","\n","    conf_layers = []\n","    conf_layers += [nn.Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    conf_layers += [nn.Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    conf_layers += [nn.Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    conf_layers += [nn.Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    conf_layers += [nn.Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","    conf_layers += [nn.Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","\n","    return vgg, extra_layers, (loc_layers, conf_layers)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5FDy4IOkM1v","colab_type":"code","colab":{}},"source":["def build_ssd(phase, size=300, num_classes=21):\n","    base_, extras_, head_ = multibox(num_classes)\n","    return SSD(phase, size, base_, extras_, head_, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfr09RK1u2lJ","colab_type":"code","colab":{}},"source":["dataset = 'VOC'\n","dataset_root = VOC_ROOT\n","batch_size = 16\n","start_iter = 0\n","num_workers = 4\n","cuda = True\n","lr = 1e-4\n","momentum = 0.9\n","weight_decay = 5e-4\n","gamma = 0.1\n","save_folder = 'weights/'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5ylq2DF0R9Z","colab_type":"code","colab":{}},"source":["def adjust_learning_rate(optimizer, gamma, step):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n","        specified step\n","    # Adapted from PyTorch Imagenet example:\n","    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n","    \"\"\"\n","    lr = lr * (gamma ** (step))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","\n","def xavier(param):\n","    init.xavier_uniform(param)\n","\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        xavier(m.weight.data)\n","        m.bias.data.zero_()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"opmNKubm0TBj","colab_type":"code","colab":{}},"source":["def train():\n","    cfg = voc\n","    dataset = VOCDetection(root=dataset_root,\n","                           transform=SSDAugmentation(cfg['min_dim'],\n","                                                     MEANS))\n","\n","    ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])\n","    net = ssd_net\n","\n","    if cuda:\n","        net = torch.nn.DataParallel(ssd_net)\n","        cudnn.benchmark = True\n","\n","    if cuda:\n","        net = net.cuda()\n","\n","    print('Initializing weights...')\n","    # initialize newly added layers' weights with xavier method\n","    ssd_net.extras.apply(weights_init)\n","    ssd_net.loc.apply(weights_init)\n","    ssd_net.conf.apply(weights_init)\n","\n","    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum,\n","                          weight_decay=weight_decay)\n","    criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,\n","                             False, cuda)\n","\n","    net.train()\n","    # loss counters\n","    loc_loss = 0\n","    conf_loss = 0\n","    epoch = 0\n","    print('Loading the dataset...')\n","\n","    epoch_size = len(dataset) // batch_size\n","    print('Training SSD on:', dataset.name)\n","\n","    step_index = 0\n","\n","\n","    data_loader = data.DataLoader(dataset, batch_size,\n","                                  num_workers=num_workers,\n","                                  shuffle=True, collate_fn=detection_collate,\n","                                  pin_memory=True)\n","    # create batch iterator\n","    batch_iterator = iter(data_loader)\n","    for iteration in range(start_iter, cfg['max_iter']):\n","        if iteration != 0 and (iteration % epoch_size == 0):\n","            loc_loss = 0\n","            conf_loss = 0\n","            epoch += 1\n","\n","        if iteration in cfg['lr_steps']:\n","            step_index += 1\n","            adjust_learning_rate(optimizer, gamma, step_index)\n","\n","        # load train data\n","        try:\n","            images, targets = next(batch_iterator)\n","        except StopIteration:\n","            batch_iterator = iter(data_loader)\n","            images, targets = next(batch_iterator)\n","        if cuda:\n","            images = Variable(images.cuda())\n","            targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n","        else:\n","            images = Variable(images)\n","            targets = [Variable(ann, volatile=True) for ann in targets]\n","        # forward\n","        t0 = time.time()\n","        out = net(images)\n","        # backprop\n","        optimizer.zero_grad()\n","        loss_l, loss_c = criterion(out, targets)\n","        loss = loss_l + loss_c\n","        loss.backward()\n","        optimizer.step()\n","        t1 = time.time()\n","        loc_loss += loss_l.data\n","        conf_loss += loss_c.data\n","\n","        if iteration % 10 == 0:\n","            print('timer: %.4f sec.' % (t1 - t0))\n","            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data), end=' ')\n","\n","\n","        if iteration != 0 and iteration % 5000 == 0:\n","            print('Saving state, iter:', iteration)\n","            torch.save(ssd_net.state_dict(), 'weights/ssd300_' +\n","                       repr(iteration) + '.pth')\n","    torch.save(ssd_net.state_dict(),\n","               save_folder + '' + dataset + '.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDAlWW7E0UOI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":892},"outputId":"a72479f5-0fa4-4496-ca25-a644c493b555","executionInfo":{"status":"error","timestamp":1576572395253,"user_tz":-540,"elapsed":149732,"user":{"displayName":"강준규","photoUrl":"","userId":"00670362314563668003"}}},"source":["train()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Initializing weights...\n","Loading the dataset...\n","Training SSD on: VOC0712\n","timer: 9.3468 sec.\n","iter 0 || Loss: 60.5361 || timer: 0.1859 sec.\n","iter 10 || Loss: 18.9157 || timer: 0.1828 sec.\n","iter 20 || Loss: 15.1747 || timer: 0.2594 sec.\n","iter 30 || Loss: 15.2182 || timer: 0.2396 sec.\n","iter 40 || Loss: 14.9558 || timer: 0.1908 sec.\n","iter 50 || Loss: 15.2420 || timer: 0.1836 sec.\n","iter 60 || Loss: 14.9179 || timer: 0.1849 sec.\n","iter 70 || Loss: 15.1396 || timer: 0.1771 sec.\n","iter 80 || Loss: 14.8052 || timer: 0.2457 sec.\n","iter 90 || Loss: 14.9239 || timer: 0.1661 sec.\n","iter 100 || Loss: 14.6687 || timer: 0.1680 sec.\n","iter 110 || Loss: 14.4892 || timer: 0.2300 sec.\n","iter 120 || Loss: 14.6413 || timer: 0.1676 sec.\n","iter 130 || Loss: 14.5213 || timer: 0.2291 sec.\n","iter 140 || Loss: 13.9567 || timer: 0.2582 sec.\n","iter 150 || Loss: 14.5301 || timer: 0.1688 sec.\n","iter 160 || Loss: 13.7863 || timer: 0.1823 sec.\n","iter 170 || Loss: 11.8692 || timer: 0.2520 sec.\n","iter 180 || Loss: 13.1458 || timer: 0.2126 sec.\n","iter 190 || Loss: 11.6712 || timer: 0.1805 sec.\n","iter 200 || Loss: 11.3911 || timer: 0.1829 sec.\n","iter 210 || Loss: 11.6758 || timer: 0.2419 sec.\n","iter 220 || Loss: 11.1917 || timer: 0.1832 sec.\n","iter 230 || Loss: 12.9901 || timer: 0.1967 sec.\n","iter 240 || Loss: 10.0747 || timer: 0.1983 sec.\n","iter 250 || Loss: 11.2519 || timer: 0.2486 sec.\n","iter 260 || Loss: 9.6895 || timer: 0.2381 sec.\n","iter 270 || Loss: 9.9485 || timer: 0.1962 sec.\n","iter 280 || Loss: 10.8100 || "],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-481594b26d46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"F9bVKXJs0Ziv","colab_type":"code","colab":{}},"source":["'''-----------------------------------------------------------------------------------------------'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mniPut-a0pb2","colab_type":"code","colab":{}},"source":["from eval import test_net"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMUdB2Et0cUK","colab_type":"code","colab":{}},"source":["num_classes = len(labelmap) + 1                      # +1 for background\n","net = build_ssd('val', 300, num_classes)            # initialize SSD\n","net.load_state_dict(torch.load(trained_model))\n","net.eval()\n","print('Finished loading model!')\n","# load data\n","dataset = VOCDetection(voc_root, [('2007', set_type)],\n","                        BaseTransform(300, dataset_mean),\n","                        VOCAnnotationTransform())\n","if cuda:\n","    net = net.cuda()\n","    cudnn.benchmark = True\n","# evaluation\n","test_net(save_folder, net, cuda, dataset,\n","          BaseTransform(net.size, dataset_mean), top_k, 300,\n","          thresh=confidence_threshold)\n"],"execution_count":0,"outputs":[]}]}